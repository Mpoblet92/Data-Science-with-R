sum(Titanic[Titanic %in% c("Sex","Yes")])
Titanic[Titanic %in% c("Sex","Yes")]
data("USArrests")
?USArrests
USArrests
USArrests$Wyoming
USArrests$Murder
USArrests["Oregon"]
USArrests[1,"Oregon"]
USArrests$Murder["Oregon"]
#Create data frame
candidates <- data.frame(Gender = c("F","M","F","F","M"),
ID = 103:107,
score = c(78, 92, 61, 92, 85))
#Create an additional column
lastName <- c("Perkins", "Patel", "Jackson", "Brown", "Wu")
#Does not change data frame
cbind(candidates,lastNames)
candidates
#Modifies data frame
candidates <- cbind(candidates,lastName)
#Accessing data frame
candidates$score
candidates[3]
candidates[3,]
candidates$score[3]
best <- max(candidates$score)
candFilter <- candidates$score==best
candFilter
candidates[candFilter]
candidates[candFilter,]
candidates$score[3] <- 92
candidates[candidates$score==best,"ID"]
candidates[candFilter,c("ID","lastName")]
#Rows can be named
row.names(candidates) <- c("A", "B", "C", "D", "E")
candidates
row.names(candidates) <- (candidates$ID + 800)
candidates
sum(Titanic[,1,,2])
USArrests$Murder["Oregon"]
USArrests$Murder[["Oregon"]]
m <- sum(Titanic[,1,,2])
# Males Survived
m
f <- sum(Titanic[,2,,2])
# Femailes Survived
f
apply(Titanic,2,sum)
(sum(Titanic[,1,,])/m)*100
(m/sum(Titanic[,1,,]))*100
sum(Titanic[,1,,])
(f/sum(Titanic[,2,,]))*100
str(USArrests)
candidates[candFilter,c("ID","lastName")]
row.names(candidates) <- c("A", "B", "C", "D", "E")
candidates
candidates[candidates$score==best,"ID"]
candidates[candFilter,c("ID","lastName")]
View(candidates)
candidates$score
candidates[3]
candidates[3,]
candidates$score[3]
view(USArrests)
View(USArrests)
nrow(USArrests)
USArrests
str(USArrests)
USArrests$Murder['Oregon']
USArrests['Oregon']
USArrests[1,'Oregon']
USArrests[1,'Oregon',,]
USArrests[1,2]
USArrests[,2]
USArrests['Oregon',1]
sum(USArrests['Vermont',c(1,2,4)])
apply(USArrests,c(1,2,4),mean)
totalArrests <- sum(USArrests[c(1,2,4)])
totalArrests
averageArrests <- mean(USArrests[c(1,2,4)])
mean(USArrests[2])
mean(USArrests[,2])
sum(USArrests['Georgia',2])
sum(USArrests['Georgia',4])
View(candidates)
Total <- USArrests$Murder + USArrests$Assault + USArrests$Rape
USArrests <- c(USArrests, Total)
USArrests
rm(list = ls())
source('G:/Data Science/Lab1_Poblet.r', echo=TRUE)
USArrests <- cbind(USArrests, Total)
USArrests
rm(list = ls())
source('G:/Data Science/Lab1_Poblet.r', echo=TRUE)
View(USArrests)
sum(USArrests['Georgia',c(2,4)])
totalArrests <- USArrests$Murder + USArrests$Assault + USArrests$Rape
USArrests <- cbind(USArrests, totalArrests)
USArrests
rm(list = ls())
USArrests
source('G:/Data Science/Lab1_Poblet.r', echo=TRUE)
rm(list = ls())
pnorm(450, mean = 496, sd = 114)
pnorm(0)      #Default is standard normal
pnorm(1.5)
pnorm(1.5, lower.tail = FALSE)
pnorm(70, mean=100, sd=15)  #Percent at 70 or below
pnorm(150, mean=100, sd=15, lower.tail = FALSE)
pnorm(c(-2, -1, 0, 1, 2))
pnorm(c(90, 100, 110, 120), mean=100, sd=15)
qnorm(.5)       #Equivalent to median value
qnorm(.25)      #Equivalent to first quartile
qnorm(.75)
qnorm(.25, lower.tail = FALSE)
qnorm(.8, mean=100, sd=15)
pnorm(580, mean = 496, sd = 114)
qnorm(.75, mean = 496, sd = 114)
qnorm(.8, mean = 496, sd = 114)
qnorm(.05, mean = 496, sd = 114, lower.tail = FALSE)
qnorm(.05, mean = 496, sd = 114)
qnorm(.05, mean = 496, sd = 114, lower.tail = FALSE)
?runif
sample <- runif(100, min = 1, max = 10)
sample
set.seed(519)
sample <- runif(100, min = 1, max = 10)
sample
set.seed(19)
sample <- runif(100, min = 1, max = 10)
sample
set.seed(519)
sample <- runif(100, min = 1, max = 10)
sample
qunif(.25)
?qunif
qunif(100, min = 1, max = 10)
qunif(.25, min = 1, max = 10)
qunif(.25, min = 1, max = 10)
sample.qunif(.25, min = 1, max = 10)
qunif(sample, min = 1, max = 10)
quantile(sample, .25)
hist(sample)
sample <- runif(1000, min = 1, max = 10)
set.seed(519)
sample <- runif(1000, min = 1, max = 10)
quantile(sample, .25)
set.seed(519)
sample <- runif(100, min = 1, max = 10)
sample <- runif(1000, min = 1, max = 10)
quantile(sample, .25)
set.seed(519)
sample <- runif(100, min = 1, max = 10)
sample_Two <- runif(1000, min = 1, max = 10)
quantile(sample_Two, .25)
host(sample_Two)
hist(sample_Two)
sample_Three <- runif(1000, min = 1, max = 10)
quantile(sample_Three, .25)
hist(sample_Three)
set.seed(519)
sample <- runif(100, min = 1, max = 10)
# 2.
qunif(.25, min = 1, max = 10)
# 3.
quantile(sample, .25)
# 4.
hist(sample)
# 5.
sample_Two <- runif(1000, min = 1, max = 10)
# 6.
quantile(sample_Two, .25)
# 7.
hist(sample_Two)
# 8.
sample_Three <- runif(1000, min = 1, max = 10)
# 9.
quantile(sample_Three, .25)
# 10.
hist(sample_Three)
set.seed(519)
sample <- runif(100, min = 1, max = 10)
# 2.
qunif(.25, min = 1, max = 10)
# 3.
quantile(sample, .25)
# 4.
hist(sample)
# 5.
sample_Two <- runif(1000, min = 1, max = 10)
# 6.
quantile(sample_Two, .25)
# 7.
hist(sample_Two)
# 8.
sample_Three <- runif(10000, min = 1, max = 10)
# 9.
quantile(sample_Three, .25)
# 10.
hist(sample_Three)
hist(sample_Three)
# 1.
set.seed(519)
sample <- runif(100, min = 1, max = 10)
# 2.
qunif(.25, min = 1, max = 10)
# 3.
quantile(sample, .25)
# 4.
hist(sample)
# 5.
sample_Two <- runif(1000, min = 1, max = 10)
# 6.
quantile(sample_Two, .25)
# 7.
hist(sample_Two)
# 8.
sample_Three <- runif(10000, min = 1, max = 10)
# 9.
quantile(sample_Three, .25)
# 10.
hist(sample_Three)
mean(sample_Three)
mean(sample_Two)
mean(sample)
rm(list = ls())
data("USJudgeRatings")
USJudgeRatings?
;
?USJudgeRatings
candidates <- data.frame(Gender = c("F","M","F","F","M"),
ID = 103:107,
score = c(78, 92, 61, 92, 85))
lastName <- c("Perkins", "Patel", "Jackson", "Brown", "Wu")
cbind(candidates,lastNames)
candidates
USJudgeRatings
USJudgeRatings
candidates <- cbind(candidates,lastName)
#Accessing data frame
candidates$score
candidates[3]
candidates[3,]
candidates$score[3]
best <- max(candidates$score)
candFilter <- candidates$score==best
candFilter
candidates[candFilter]
candidates[candFilter,]
candidates$score[3] <- 92
candidates[candidates$score==best,"ID"]
candidates[candFilter,c("ID","lastName")]
#Rows can be named
row.names(candidates) <- c("A", "B", "C", "D", "E")
candidates
row.names(candidates) <- (candidates$ID + 800)
candidates
candidates[candFilter,c("ID","lastName")]
candidates[candidates$score==best,"ID"]
candidates[candFilter,c("ID","lastName")]
topJudges <- data.frame(USJudgeRatings = 1:12)
View(USJudgeRatings)
View(USJudgeRatings)
View(topJudges)
View(topJudges)
View(USJudgeRatings)
topJudges <- data.frame(USJudgeRatings(,1:12))
topJudges <- data.frame(USJudgeRatings[,1:12])
candidates[candFilter,c("ID","lastName")]
candidates[candFilter]
candidates[candFilter,]
candidates$score[3] <- 92
candidates[candidates$score==best,"ID"]
candidates[candFilter,c("ID","lastName")]
candidates$score
candidates[3]
candidates[3,]
candidates$score[3]
best <- max(candidates$score)
candFilter <- candidates$score==best
candFilter
candidates[candFilter]
candidates[candFilter,]
candidates
candidates[candFilter,c("ID","lastName")]
topJudges <- data.frame(1:12)
USJudgeRatings$CONT
USJudgeRatings[,2]
max(USJudgeRatings[,1])
max(USJudgeRatings[,2])
?which.max
?pmax
pmax(3:1, USJudgeRatings$CONT)
?max
max(3:1, USJudgeRatings$CONT)
max(3:1, USJudgeRatings[,1])
max(3, USJudgeRatings[,1])
shiny::runApp('G:/Data Science/Data-Science-with-R/Labs/Lab8_Poblet')
runApp('G:/Data Science/Data-Science-with-R/Labs/Lab8_Poblet')
?plotOutput
runApp('G:/Data Science/Data-Science-with-R/Labs/Lab8_Poblet')
?sliderInput
runApp('G:/Data Science/Examples/Shiny R/Code_Part1')
runApp('G:/Data Science/Data-Science-with-R/Labs/Lab8_Poblet')
runApp('G:/Data Science/Data-Science-with-R/Labs/Lab8_Poblet')
runApp('G:/Data Science/Data-Science-with-R/Labs/Lab8_Poblet')
runApp('G:/Data Science/Examples/Shiny R/Code_Part1')
runApp('G:/Data Science/Data-Science-with-R/Labs/Lab8_Poblet')
?plot
runApp('G:/Data Science/Data-Science-with-R/Labs/Lab8_Poblet')
runApp('G:/Data Science/Examples/Shiny R/Code_Part1/first app/App')
?rnorm
runApp('G:/Data Science/Data-Science-with-R/Labs/Lab8_Poblet')
?runof
?runif
runApp('G:/Data Science/Data-Science-with-R/Labs/Lab8_Poblet')
runApp('G:/Data Science/Data-Science-with-R/Labs/Lab8_Poblet')
runApp('G:/Data Science/Data-Science-with-R/Labs/Lab8_Poblet')
print(source('G:/Data Science/Examples/Shiny R/Code_Part1/02-hist-app.R')$value)
print(source('G:/Data Science/Examples/Shiny R/Code_Part2/01-two-inputs.R')$value)
runApp('G:/Data Science/Data-Science-with-R/Labs/Lab8_Poblet')
runApp('G:/Data Science/Data-Science-with-R/Labs/Lab8_Poblet')
rnorm(5)
IQ_list <- rnorm(200,mean=100,sd=15)
runApp('G:/Data Science/Data-Science-with-R/Labs/Lab8_Poblet')
?plot
plotOutput()
?plotOutput
runApp('G:/Data Science/Data-Science-with-R/Labs/Lab8_Poblet')
runApp('G:/Data Science/Examples/Shiny R/Code_Part1/first app/App')
runApp('G:/Data Science/Data-Science-with-R/Labs/Lab8_Poblet')
runApp('G:/Data Science/Examples/Shiny R/Code_Part1/first app/App')
runApp('G:/Data Science/Data-Science-with-R/Labs/Lab8_Poblet')
?sidebarLayout
runApp('G:/Data Science/Data-Science-with-R/Labs/Lab8_Poblet')
---
install.packages("kernlab")
install.packages("caret")
install.packages('caret', dependencies = TRUE)
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(kernlab)
library(caret)
weightLift <- read.csv("weightlift.csv")
setwd("G:/Data Science/Data-Science-with-R/Projects/Project 7")
weightLift <- read.csv("weightlift.csv")
View(weightLift)
set.seed(519)
inTraining <- createDataPartition(y=weightLift$classe, p=0.25, list=FALSE)
trainginData <- weightLift[inTraining,]
validataionData <- weightLift[-inTraining,]
rfModel <- train(classe ~ ., data = weightLift, method="rf", trControl=trainOpts, prox=TRUE)
library(randomForest)
rfModel <- train(classe ~ ., data = weightLift, method="rf", trControl=trainOpts, prox=TRUE)
trainOpts <- trainControl()
trainOpts$method="cv"
trainOpts$number=3
rfModel <- train(classe ~ ., data = weightLift, method="rf", trControl=trainOpts, prox=TRUE)
rfModel
cm <- confusionMatrix(rfModel$finalModel@predicted, trainingData$classes)
cm <- confusionMatrix(rfModel$finalModel$predicted, trainingData$classes)
trainingData <- weightLift[inTraining,]
cm <- confusionMatrix(rfModel$finalModel$predicted, trainingData$classes)
cm <- confusionMatrix(rfModel$finalModel$predicted, trainingData$classe)
cm <- confusionMatrix(rfModel$finalModel$predicted,trainingData$classe)
cm <- confusionMatrix(rfModel$finalModel$predicted,trainingData$classe)
View(inTraining)
View(trainginData)
cm <- confusionMatrix(rfModel$finalModel$predicted,trainingData$classe)
rm(list=ls())
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(kernlab)
library(caret)
library(randomForest)
weightLift <- read.csv("weightlift.csv")
trainOpts <- trainControl()
trainOpts$method="cv"
trainOpts$number=3
set.seed(519)
inTraining <- createDataPartition(y=weightLift$classe, p=0.25, list=FALSE)
trainingData <- weightLift[inTraining,]
validataionData <- weightLift[-inTraining,]
rfModel <- train(classe ~ ., data = weightLift, method="rf", trControl=trainOpts, prox=TRUE)
rfModel
cm <- confusionMatrix(rfModel$finalModel$predicted,trainingData$classe)
rm(list=ls())
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(kernlab)
library(caret)
library(randomForest)
weightLift <- read.csv("weightlift.csv")
trainOpts <- trainControl()
trainOpts$method="cv"
trainOpts$number=3
set.seed(519)
inTraining <- createDataPartition(y=weightLift$classe, p=0.25, list=FALSE)
trainingData <- weightLift[inTraining,]
validataionData <- weightLift[-inTraining,]
rfModel <- train(classe ~ ., data = trainingData, method="rf", trControl=trainOpts, prox=TRUE)
rfModel
cm <- confusionMatrix(rfModel$finalModel$predicted,trainingData$classe)
cm$table
cm$overall[1]
priority <- varImp(rfModel)
print(priority)
str(priority)
print(priority[1:30])
print(priority[c(1:50)])
str(priority)
sorting <- order(priority$importance$Overall,decreasing = TRUE)
keep <- row.names(priority$importance)[sort[1:30]]
keep <- row.names(priority$importance)[sorting[1:30]]
validataionData <- validataionData[,c(keep,"type")]
validataionData <- validataionData[,c(keep,"classe")]
colnames(validataionData)
inTraining <- createDataPartition(y=validationData$type, p=0.6, list = FALSE)
inTraining <- createDataPartition(y=validationData$classe, p=0.6, list = FALSE)
validataionData <- validataionData[,c(keep,"classe")]
colnames(validataionData)
inTraining <- createDataPartition(y=validationData$classe, p=0.6, list = FALSE)
validationData <- validataionData[,c(keep,"classe")]
inTraining <- createDataPartition(y=validationData$classe, p=0.6, list = FALSE)
trainingAgain <- validationData[inTraining,]
testing <- validataionData[-inTraining,]
rfModel2 <- train(classe ~ ., data = trainingAgain, method="rf", trControl=trainOpts)
rfModel2
rfModel2$finalModel
testPredict <- predict(rfModel2,testing)
confusionMatrix(testPredict,testing$classe)$table
confusionMatrix(testPredict,testing$classe)$overall[1]
colnames(weightLift)
weightLift <- weightLift[,2]
colnames(weightLift)
weightLift <- read.csv("weightlift.csv")
weightLift <- weightLift[,-"x"]
weightLift <- weightLift[,-rownames(x)]
weightLift <- read.csv("weightlift.csv")
weightLift <- weightLift[,-weightLift$X]
colnames(weightLift)
weightLift <- read.csv("weightlift.csv")
weightLift <- weightLift[-weightLift$X]
colnames(weightLift)
weightLift <- read.csv("weightlift.csv")
colnames(weightLift)
weightLift[,1]
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(ggplot2)
library(kernlab)
library(caret)
library(randomForest)
weightLift <- read.csv("weightlift.csv")
weightLift <- select(weightLift, -X)
colnames(weightLift)
weightLift <- read.csv("weightlift.csv")
weightLift <- select(weightLift, -c(X, new_window, num_window))
colnames(weightLift)
View(weightLift)
set.seed(519)
inTraining <- createDataPartition(y=weightLift$classe, p=0.25, list=FALSE)
trainingData <- weightLift[inTraining,]
validataionData <- weightLift[-inTraining,]
rfModel <- train(classe ~ ., data = trainingData, method="rf", trControl=trainOpts, prox=TRUE)
rfModel
inTraining <- createDataPartition(y=weightLift$classe, p=0.40, list=FALSE)
trainingData <- weightLift[inTraining,]
validataionData <- weightLift[-inTraining,]
rfModel <- train(classe ~ ., data = trainingData, method="rf", trControl=trainingOptions, prox=TRUE)
trainingOptions <- trainControl()
trainingOptions$method="cv"
trainingOptions$number=3
rfModel <- train(classe ~ ., data = trainingData, method="rf", trControl=trainingOptions, prox=TRUE)
rfModel
rfModel$results
rfModel$results$Accuracy
rfModel$results$Accuracy[2]
rfModel$metric
max(rfModel$results$Accuracy)
cm <- confusionMatrix(rfModel$finalModel$predicted,trainingData$classe)
cm$table
cm$overall[1]
priority <- varImp(rfModel)
print(priority[c(1:50)])
print(priority)
print(priority$importance)
sorting <- order(priority$importance$Overall,decreasing = TRUE)
keep <- row.names(priority$importance)[sorting[1:15]]
validationData <- validataionData[,c(keep,"classe")]
colnames(validataionData)
colnames(validationData)
inTraining <- createDataPartition(y=validationData$classe, p=0.6, list = FALSE)
trainingAgain <- validationData[inTraining,]
testing <- validataionData[-inTraining,]
rfModel2 <- train(classe ~ ., data = trainingAgain, method="rf", trControl=trainingOptions)
rfModel2
max(rfModel2$results$Accuracy)
rfModel2$finalModel
testPredict <- predict(rfModel2,testing)
confusionMatrix(testPredict,testing$classe)$table
confusionMatrix(testPredict,testing$classe)$overall[1]
rfModel2$finalModel
rfModel2$finalModel$predicted
The results yielded `r max(rfModel2$results$Accuracy)` Accuracy.
rfModel2$finalModel$err.rate
rfModel2$finalModel$mtry
rfModel2$finalModel
cm <- confusionMatrix(rfModel2$finalModel$predicted,trainingAgain$classe)
cm$overall[1]
rm(list = ls())
